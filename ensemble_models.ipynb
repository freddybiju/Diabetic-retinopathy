{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libs..\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.applications import Xception\n",
    "from keras.applications import DenseNet201\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import BatchNormalization, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping,ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import roc_auc_score,precision_recall_fscore_support\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as k\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from tensorflow.compat.v1.keras.backend import clear_session\n",
    "from tensorflow.compat.v1.keras.backend import get_session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load  Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D:\\RahanaMSc\\Projects\\DR_F\\scripts01\\input\n",
    "\n",
    "y = np.load('C:/Users/fredd/Downloads/aptos2019-blindness-detection/y_train.npy')\n",
    "x = np.load('C:/Users/fredd/Downloads/aptos2019-blindness-detection/X_train_256.npy')\n",
    "x_test_pred = np.load('C:/Users/fredd/Downloads/aptos2019-blindness-detection/X_test_256.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:/Users/fredd/Downloads/aptos2019-blindness-detection/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_o, x_test, y_train_o, y_test = train_test_split(x, y,test_size = 0.10,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o.shape,x_test.shape, y_train_o.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_o, y_train_o,test_size = 0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape,x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs=3\n",
    "batch_size=32\n",
    "fine_tune_epochs=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it does something you should see a number as output\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tensorflow.compat.v1.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tensorflow.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_gen = ImageDataGenerator(\n",
    "        width_shift_range=0.2, height_shift_range=0.2,\n",
    "        horizontal_flip=True,   # randomly flip images\n",
    "        vertical_flip=True,     # randomly flip images\n",
    "        rotation_range=60 ,      # Degree range for random rotations\n",
    "        zoom_range=0.2, shear_range=0.2, fill_mode='nearest')\n",
    "\n",
    "valid_data_gen = ImageDataGenerator()\n",
    "\n",
    "# Using original generator\n",
    "train_generator = train_data_gen.flow(x_train, y_train,batch_size=batch_size,seed=2019)\n",
    "\n",
    "valid_generator = valid_data_gen.flow(x_val, y_val,batch_size=batch_size,seed=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(nrows=1,ncols=7,figsize=(18,8))\n",
    "i = 0\n",
    "aug = ['width_shift_range','height_shift_range','horizontal_flip','vertical_flip','rotation_range','zoom_range','shear_range']\n",
    "#for img_iterator in datagen.flow(x = img_arr,batch_size = 1):\n",
    "for x,y in train_data_gen.flow(x_train, y_train): \n",
    "    ax[i].set_title(\"{}\".format(aug[i]), size=16)\n",
    "    ax[i].imshow((x[0].astype('uint8'))) \n",
    "    ax[i].axis('off')  \n",
    "    \n",
    "    i = i + 1\n",
    "    if i == 7:\n",
    "        break\n",
    "#fig.savefig(\"images_pre/Aug_21.png\",dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('G/APTOS/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['image'] = [i + '.png' for i in train['id_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_PATH ='G/APTOS/train-final-256/' \n",
    "train['file_path'] = train['id_code'].map(lambda x: os.path.join(TRAIN_PATH,'{}.png'.format(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(nrows=1,ncols=8,figsize=(30,10))\n",
    "i = 0\n",
    "img = cv2.imread(train.file_path.iloc[np.random.randint(low = 0,high = len(train) - 1)])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (256,256))\n",
    "img_arr = img.reshape((1,) + img.shape)\n",
    "ax[i].set_title(\"original_image\", size=16)\n",
    "ax[i].imshow(img)\n",
    "ax[i].axis(\"off\")\n",
    "# plt.rcParams[\"axes.grid\"] = False\n",
    "i = i + 1\n",
    "aug = ['width_shift_range','height_shift_range','horizontal_flip','vertical_flip','rotation_range','zoom_range','shear_range']\n",
    "for img_iterator in train_data_gen.flow(x = img_arr,batch_size = 1):\n",
    "# for x,y in train_data_gen.flow(x_train, y_train): \n",
    "    ax[i].set_title(\"{}\".format(aug[i-1]), size=16)\n",
    "    ax[i].imshow((x[0].astype('uint8'))) \n",
    "    ax[i].axis('off')  \n",
    "    \n",
    "    i = i + 1\n",
    "    if i == 8:\n",
    "        break\n",
    "#fig.savefig(\"images_pre/Aug_21_New.png\",dpi=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = keras.applications.VGG16(weights='imagenet',include_top=False, input_shape=(256,256,3))\n",
    "resnet=keras.applications.ResNet50(weights='imagenet',include_top=False, input_shape=(256,256,3)) \n",
    "densenet=keras.applications.DenseNet201(weights='imagenet',include_top=False, input_shape=(256,256,3))\n",
    "inceptnet=keras.applications.InceptionV3(weights='imagenet',include_top=False, input_shape=(256,256,3))\n",
    "incept_resnet=keras.applications.InceptionResNetV2(weights='imagenet',include_top=False, input_shape=(256,256,3))\n",
    "xceptnet=keras.applications.Xception(weights='imagenet',include_top=False, input_shape=(256,256,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define & Train the Model\n",
    "\n",
    "### Feature-Extraction\n",
    "\n",
    "If performing fine tuning directly would result in a huge gradient, so it's better that we perform 3 epochs of feature extraction first so that weights of the final fully connected layer aren't completely random. The intuition for this is that if we don't perform feature-extraction, then the gradient will be too large and will change the pretrained weights too much.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Initial_Training_1(base_model,name):\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        print(layer.name)\n",
    "        layer.trainable = False\n",
    "        \n",
    "    print(len(base_model.layers))\n",
    "   \n",
    "\n",
    "    # Get the output from the base model \n",
    "    base_model_ouput = base_model.layers[-1].output\n",
    "\n",
    "    x = layers.BatchNormalization()(base_model_ouput)\n",
    "    # Flatten the output layer to 1 dimension\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "     # Add a dropout rate of 0.5\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    # Add a dropout rate of 0.5\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    # Add a final sigmoid layer for classification\n",
    "    x = layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "    # Configure and compile the model\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=x,name=name)\n",
    "\n",
    "    optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "                \n",
    "    model.summary()\n",
    "\n",
    "    history= model.fit_generator(train_generator,\n",
    "    steps_per_epoch=train_generator.n//batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.n//batch_size,\n",
    "    epochs=initial_epochs,verbose=1)\n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Initial_Training_2(base_model,name):\n",
    "\n",
    "  #Reset the batch norm moving averages and allow them to update to the new dataset\n",
    "  \n",
    "    for layer in base_model.layers:\n",
    "        print(layer.name)\n",
    "        if hasattr(layer, 'moving_mean') and hasattr(layer, 'moving_variance'):\n",
    "            layer.trainable = True\n",
    "            K.eval(K.update(layer.moving_mean, K.zeros_like(layer.moving_mean)))\n",
    "            K.eval(K.update(layer.moving_variance, K.zeros_like(layer.moving_variance)))\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "\n",
    "    print(len(base_model.layers))\n",
    "\n",
    "    \n",
    "    # Get the output from the base model \n",
    "   \n",
    "    base_model_ouput = base_model.layers[-1].output\n",
    "\n",
    "    x = layers.BatchNormalization(name=name+'_BN')(base_model_ouput)\n",
    "    # Flatten the output layer to 1 dimension\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "     # Add a dropout rate of 0.5\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    # Add a fully connected layer with 1024 hidden units and ReLU activation\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    # Add a dropout rate of 0.5\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    # Add a final sigmoid layer for classification\n",
    "    x = layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "    # Configure and compile the model\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=x,name=name)\n",
    "\n",
    "    optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    history= model.fit_generator(train_generator,\n",
    "    steps_per_epoch=train_generator.n//batch_size,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.n//batch_size,\n",
    "    epochs=initial_epochs,\n",
    "    verbose=1)\n",
    "    \n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning Model\n",
    "\n",
    "Let's fine tune the last convolutional block of network. I only use learning_rate = 0.0001 with very high momentum = 0.9 and train for 40 epochs only so that the original weights of pretrained network won't be changed too much. learning_rate_reduction function is used and will halve the learning_rate whenever the validation accuracy plateaus for 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def model_finetuning(model,batch_size,split_at,model_path):\n",
    "\n",
    "    #epochs = 30\n",
    "\n",
    "    # training the model after 15 layers\n",
    "   \n",
    "    for layer in model.layers[:split_at]: layer.trainable = False\n",
    "    for layer in model.layers[split_at:]: layer.trainable = True\n",
    "        \n",
    "   \n",
    "    # Choosing lower learning rate for fine-tuning\n",
    "    # learning rate is generally 10-1000 times lower than normal learning rate when we are fine tuning the initial layers\n",
    "    optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, \n",
    "                                                min_lr=0.000001, cooldown=3)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only = True, mode ='auto', verbose = 1)\n",
    "\n",
    "    batch_size = 32\n",
    "    epochs = 40\n",
    "    start_time = time.time()\n",
    "    history_finetune = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n//batch_size,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=valid_generator.n//batch_size,\n",
    "        epochs=fine_tune_epochs,\n",
    "        verbose=1, callbacks=[learning_rate_reduction,checkpoint])\n",
    "    print(\"\\n\")\n",
    "    print(\"Time taken for training the model: {} seconds\".format(np.round(time.time()-start_time,5)))\n",
    "    return model,history_finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history,model_name):\n",
    "    loss_list = [s for s in model_history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in model_history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in model_history.history.keys() if 'accuracy' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in model_history.history.keys() if 'accuracy' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(model_history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    #fig = plt.figure()\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, model_history.history[l], 'b', label='Training loss')\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, model_history.history[l], 'g', label='Validation loss')\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    # plt.legend(['Training set', 'Validation set'], loc='best')\n",
    "    plt.legend()\n",
    "    plt.savefig('images/New_'+ model_name+'_loss.jpg',dpi=96)\n",
    "\n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "   \n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, model_history.history[l], 'b', label='Training accuracy' )\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, model_history.history[l], 'g', label='Validation accuracy')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    #plt.legend(['Training set', 'Validation set'], loc='best')\n",
    "    plt.legend()\n",
    "    plt.savefig('images/New_'+ model_name+'_accuracy.jpg',dpi=96)\n",
    "\n",
    "    #plt.close(fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performace_evaluate(model):\n",
    "\n",
    "    loss, accuracy = model.evaluate(x_train, y_train, verbose=1)\n",
    "    loss_v, accuracy_v = model.evaluate(x_val, y_val, verbose=1)\n",
    "    print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n",
    "    print(\"Train: accuracy = %f  ;  loss = %f\" % (accuracy, loss))\n",
    "\n",
    "    # Make a prediction on the test set\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(x_val)\n",
    "    print(\"\\n\")\n",
    "    print(\"Time taken for predicting the model: {} seconds\".format(np.round(time.time()-start_time,5)))\n",
    "    y_pred1 = np.round(y_pred)\n",
    "\n",
    "    #y_pred_class = np.argmax(y_pred1,axis = 1)\n",
    "    y_pred_class = np.argmax(y_pred,axis = 1)\n",
    "\n",
    "    y_true = np.argmax(y_val,axis = 1) \n",
    "\n",
    "    cm = confusion_matrix(y_true,y_pred_class)\n",
    "    print(\"\\n Confusion Matrix \\n\")\n",
    "    print(cm)\n",
    "\n",
    "    # Check the Classification Report\n",
    "    print(\"\\n Classification Report \\n\")\n",
    "    print(classification_report(y_val, y_pred1))\n",
    "    \n",
    "    #def plot_conf_matrix(true,pred,classes):\n",
    "    labels = ['0 - No DR', '1 - Mild', '2 - Moderate', '3 - Severe', '4 - Proliferative DR']\n",
    "    \n",
    "\n",
    "    df_cm = pd.DataFrame(cm, range(len(labels)), range(len(labels)))\n",
    "    plt.figure(figsize=(8,5.5))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},xticklabels = labels ,yticklabels = labels,fmt='g')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.show()\n",
    "\n",
    "    accuracy= accuracy_score(y_true, y_pred_class)\n",
    "    print('Accuracy: {}'.format(accuracy))\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_pred_class, average='weighted')\n",
    "    print('precision: {}'.format(precision))\n",
    "    print('recall: {}'.format(recall))\n",
    "    print('fscore: {}'.format(fscore))\n",
    "\n",
    "\n",
    "    y_predNew = y_pred.astype(int).sum(axis=1) - 1\n",
    "\n",
    "    #from sklearn.metrics import cohen_kappa_score\n",
    "    kappa_score = cohen_kappa_score(\n",
    "                y_true,\n",
    "                y_pred_class, \n",
    "                weights='quadratic'\n",
    "            )\n",
    "    print('QWK Score: {}'.format(kappa_score))\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"\\n Predicting labels using validation dataset\\n\\n\")\n",
    "\n",
    "    #labels=['Class 0','Class 1','Class 2','Class 3','Class 4']\n",
    "    labels=['No DR','Mild DR','Moderate DR','Severe DR','PDR']\n",
    "\n",
    "    columns=4\n",
    "    rows=3      \n",
    "\n",
    "    fig, axes = plt.subplots(ncols=columns, nrows=rows, figsize=(12, 8))\n",
    "    # plt.subplots_adjust(top = 0.9, bottom=0.01, hspace=1.4, wspace=0.1)#\n",
    "   \n",
    "    index=0\n",
    "    for i in range(3):\n",
    "        for j in range(4):\n",
    "           \n",
    "            axes[i,j].set_title(\"True: {}\\nPredicted: {}\".format(labels[y_pred_class[index]],labels[y_true[index]]),size=16)\n",
    "            axes[i,j].imshow(x_val[index], cmap='gray')\n",
    "            axes[i,j].get_xaxis().set_visible(False)\n",
    "            axes[i,j].get_yaxis().set_visible(False)\n",
    "            index += 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(model):\n",
    "\n",
    "    \n",
    "     # Make a prediction on the test set\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"\\n\")\n",
    "    print(\"Time taken for predicting the model: {} seconds\".format(np.round(time.time()-start_time,5)))\n",
    "    y_pred1 = np.round(y_pred)\n",
    "\n",
    "    #y_pred_class = np.argmax(y_pred1,axis = 1)\n",
    "    y_pred_class = np.argmax(y_pred,axis = 1)\n",
    "\n",
    "    y_true = np.argmax(y_test,axis = 1) \n",
    "\n",
    "    cm = confusion_matrix(y_true,y_pred_class)\n",
    "    print(\"\\n Confusion Matrix \\n\")\n",
    "    print(cm)\n",
    "\n",
    "    # Check the Classification Report\n",
    "    print(\"\\n Classification Report \\n\")\n",
    "    print(classification_report(y_test, y_pred1))\n",
    "    \n",
    "    #def plot_conf_matrix(true,pred,classes):\n",
    "    labels = ['0 - No DR', '1 - Mild', '2 - Moderate', '3 - Severe', '4 - Proliferative DR']\n",
    "    \n",
    "\n",
    "    df_cm = pd.DataFrame(cm, range(len(labels)), range(len(labels)))\n",
    "    plt.figure(figsize=(8,5.5))\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16},xticklabels = labels ,yticklabels = labels,fmt='g')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.show()\n",
    "\n",
    "    accuracy= accuracy_score(y_true, y_pred_class)\n",
    "    print('Accuracy: {}'.format(accuracy))\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_true, y_pred_class, average='weighted')\n",
    "    print('precision: {}'.format(precision))\n",
    "    print('recall: {}'.format(recall))\n",
    "    print('fscore: {}'.format(fscore))\n",
    "\n",
    "\n",
    "    y_predNew = y_pred.astype(int).sum(axis=1) - 1\n",
    "\n",
    "    #from sklearn.metrics import cohen_kappa_score\n",
    "    kappa_score = cohen_kappa_score(\n",
    "                y_true,\n",
    "                y_pred_class, \n",
    "                weights='quadratic'\n",
    "            )\n",
    "    print('QWK Score: {}'.format(kappa_score))\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"\\n Predicting labels using validation dataset\\n\\n\")\n",
    "\n",
    "    #labels=['Class 0','Class 1','Class 2','Class 3','Class 4']\n",
    "    class_labels=['No DR','Mild DR','Moderate DR','Severe DR','PDR']\n",
    "\n",
    "    columns=4\n",
    "    rows=3      \n",
    "\n",
    "    fig, axes = plt.subplots(ncols=columns, nrows=rows, figsize=(12, 8))\n",
    "    # fig, axes = plt.subplots(ncols=4, nrows=3, figsize=(16,10))\n",
    "    # plt.subplots_adjust(top = 0.9, bottom=0.01, hspace=1.4, wspace=0.2)#\n",
    " \n",
    "\n",
    "    index=0\n",
    "    for i in range(3):\n",
    "        for j in range(4):\n",
    "          \n",
    "            axes[i,j].set_title(\"True: {}\\nPredicted: {}\".format(class_labels[y_pred_class[index]],class_labels[y_true[index]]),size=16)\n",
    "            axes[i,j].imshow(x_val[index], cmap='gray')\n",
    "            axes[i,j].get_xaxis().set_visible(False)\n",
    "            axes[i,j].get_yaxis().set_visible(False)\n",
    "            index += 1\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(model):\n",
    "\n",
    "    y_test = model.predict(x_test_pred,verbose=1)\n",
    "    predictions = [np.argmax(pred) for pred in y_test]\n",
    "\n",
    "    model_to_submit = pd.DataFrame({\n",
    "        'id_code':test['id_code'],\n",
    "        'diagnosis':predictions\n",
    "    })\n",
    "\n",
    "    print(\"\\n Distribution of predicted label \\n\")\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    f, ax = plt.subplots(figsize=(14, 8.7))\n",
    "    ax = sns.countplot(x=\"diagnosis\", data=model_to_submit, palette=\"GnBu_d\")\n",
    "    sns.despine()\n",
    "    ax.set_title(\"Distribution of predicted label\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"\\n Predicting labels using Test dataset\\n\\n\")\n",
    "\n",
    "    #def display_samples(df,\n",
    "    columns=4\n",
    "    rows=3\n",
    "\n",
    "    fig=plt.figure(figsize=(5*columns, 4*rows))\n",
    "    #fig=plt.figure(figsize=(12,8))\n",
    "    #fig=plt.figure(figsize=(15, 8))\n",
    "    #plt.subplots_adjust (hspace=1.4)\n",
    "\n",
    "    for i in range(columns*rows):\n",
    "        image_path = test.loc[i,'id_code']\n",
    "        #print(image_path)\n",
    "        image_id = model_to_submit.loc[i,'diagnosis']\n",
    "        \n",
    "        if image_id==0:\n",
    "            val=\"No DR\"\n",
    "        elif image_id==1:\n",
    "            val=\"Mild DR\"\n",
    "        elif image_id==2:\n",
    "            val=\"Moderate DR\"\n",
    "        elif image_id==3:\n",
    "            val=\"Severe DR\"   \n",
    "        elif image_id==4:\n",
    "            val=\"Proliferative DR\"    \n",
    "        img = cv2.imread(f'G/APTOS/test-final-256/{image_path}.png')\n",
    "        #print(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        \n",
    "        plt.title(\"Image={image_path}.png \\nDiagnosis={image_id}\".format(image_path=image_path, image_id=val),size=16)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model,vgg_history= Initial_Training_1(vgg,\"Vgg_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_FT,vgg_FT_history=model_finetuning(vgg_model,32,15,'vgg16.h5')\n",
    "vgg_FT.save('vgg16_Full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_FT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(vgg_FT_history,\"Vgg16\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performace_evaluate(vgg_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make prediction on Unseen Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(vgg_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make prediction on Test Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels(vgg_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnet_model,resnet_history= Initial_Training_1(resnet,\"resnet_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_FT,resnet_FT_history=model_finetuning(resnet_model,32,140,'resnet.h5')\n",
    "resnet_FT.save('resnet_Full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_FT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(resnet_FT_history,\"resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performace_evaluate(resnet_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluate Performance on Unseen Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(resnet_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluate Performance on Unseen Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels(resnet_FT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gc.collect()\n",
    "reset_keras()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model,densenet_history= Initial_Training_1(densenet,\"densenet_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_FT,densenet_FT_history=model_finetuning(densenet_model,32,481,'densenet.h5')\n",
    "densenet_FT.save('densenet_Full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_FT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(densenet_FT_history,\"densenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_history(densenet_FT_history,,\"densenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performace_evaluate(densenet_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluate Performance on Unseen Test Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(densenet_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make prediction on Test Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_labels(densenet_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inceptnet_model,incept_history= Initial_Training_2(inceptnet,\"incept_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incept_FT,incept_FT_history=model_finetuning(inceptnet_model,32,249,'incept.h5')\n",
    "incept_FT.save('incept_Full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incept_FT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(incept_FT_history,\"InceptionV3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_history(incept_FT_history) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performace_evaluate(incept_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluate Performance on Unseen Test Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(incept_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make prediction on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels(incept_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incept_resnet_model, incept_resnet_history= Initial_Training_2(incept_resnet,\"incept_res_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep_res_FT,incep_res_FT_history=model_finetuning(incept_resnet_model,32,618,'incep_res.h5')\n",
    "incep_res_FT.save('incep_res_Full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep_res_FT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(incep_res_FT_history,\"InceptionResNetV2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_history(incep_res_FT_history) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performace_evaluate(incep_res_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluate Performance on Unseen Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(incep_res_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make prediction on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels(incep_res_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xceptnet_model,xcept_history= Initial_Training_2(xceptnet,\"xcept_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xceptnet_FT,xceptnet_FT_history=model_finetuning(xceptnet_model,32,116,'Xcept.h5')\n",
    "xceptnet_FT.save('Xcept_Full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xceptnet_FT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(xceptnet_FT_history,\"Xception\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_history(xceptnet_FT_history) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performace_evaluate(xceptnet_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluate Performance on Unseen Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(xceptnet_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make prediction on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels(xceptnet_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg_FT=load_model('vgg16_full.h5')\n",
    "# resnet_FT=load_model('resnet_full.h5')\n",
    "# densenet_FT=load_model('densenet_full.h5')\n",
    "# incept_FT=load_model('incept_full.h5')\n",
    "# incep_res_FT=load_model('incep_res_full.h5')\n",
    "# xceptnet_FT=load_model('xcept_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembleModels(models, model_input,name):\n",
    "    # collect outputs of models in a list\n",
    "    yModels=[model(model_input) for model in models] \n",
    "    # averaging outputs\n",
    "    yAvg=layers.average(yModels) \n",
    "    # build model from same input and avg output\n",
    "    modelEns = Model(inputs=model_input, outputs=yAvg,name=name)  \n",
    "   #,    name='ensemble'\n",
    "    return modelEns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models= [vgg_FT,resnet_FT,densenet_FT,incept_FT,incep_res_FT,xceptnet_FT]\n",
    "model_input = Input(shape=all_models[0].input_shape[1:]) # c*h*w\n",
    "modelEns = ensembleModels(all_models, model_input,\"Ensemble_All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEns.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "modelEns.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performace_evaluate(modelEns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performace_evaluate(modelEns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEns.save('modelEns_all_full.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluate Performance on Unseen Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(modelEns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Make prediction on Test Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_labels(modelEns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble model - Except ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_R= [vgg_FT,densenet_FT,incept_FT,incep_res_FT,xceptnet_FT]\n",
    "model_input_R = Input(shape=all_models_R[0].input_shape[1:]) # c*h*w\n",
    "modelEns_R = ensembleModels(all_models_R, model_input_R,\"Ensemble_ExRes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "modelEns_R.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performace_evaluate(modelEns_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEns_R.save('modelEns_R.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model - Except DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_D= [vgg_FT,resnet_FT,incept_FT,incep_res_FT,xceptnet_FT]\n",
    "model_input_D = Input(shape=all_models_D[0].input_shape[1:]) # c*h*w\n",
    "modelEns_D = ensembleModels(all_models_D, model_input_D,\"Ensemble_ExDense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "modelEns_D.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performace_evaluate(modelEns_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(modelEns_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_labels(modelEns_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEns_D.save('modelEns_D.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = modelEns.predict(x_test_pred,verbose=1)\n",
    "predictions = [np.argmax(pred) for pred in y_test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:/Users/fredd/Downloads/aptos2019-blindness-detection/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['diagnosis'] = predictions\n",
    "test.to_csv('modelEnsemble.csv',index=False)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "f, ax = plt.subplots(figsize=(14, 8.7))\n",
    "ax = sns.countplot(x=\"diagnosis\", data=test, palette=\"GnBu_d\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def display_samples(df,\n",
    "columns=4\n",
    "rows=3\n",
    "\n",
    "fig=plt.figure(figsize=(5*columns, 4*rows))\n",
    "#fig=plt.figure(figsize=(15, 8))\n",
    "for i in range(columns*rows):\n",
    "    image_path = test.loc[i,'id_code']\n",
    "    #print(image_path)\n",
    "    image_id = test.loc[i,'diagnosis']\n",
    "    if image_id==0:\n",
    "        val=\"No DR\"\n",
    "    elif image_id==1:\n",
    "        val=\"Mild DR\"\n",
    "    elif image_id==2:\n",
    "        val=\"Moderate DR\"\n",
    "    elif image_id==3:\n",
    "        val=\"Severe DR\"   \n",
    "    elif image_id==4:\n",
    "        val=\"Proliferative DR\"    \n",
    "    img = cv2.imread(f'G/APTOS/test-final-256/{image_path}.png')\n",
    "    #print(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    #plt.title([\"Image:\" image_path \"Label = \"+image_id])\n",
    "    plt.title(\"Image={image_path}.png \\nDiagnosis={image_id}\".format(image_path=image_path, image_id=val))\n",
    "    #plt.title(image_path)\n",
    "    #plt.title(image_id)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARISON WITH OTHER WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "model = [97.8, 97.8, 97.8, 97.8]\n",
    "model_qumar = [80.8, 63.8, 51.5, 53.7]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "rects1 = ax.bar(x - width/2, model, width, label='proposed model')\n",
    "rects2 = ax.bar(x + width/2, model_qumar, width, label='Qummar et al')\n",
    "\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Comparison with S.Qummar model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend(loc='center')\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}%'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "model = [97.8, 97.8, 97.8, 97.8]\n",
    "model_qumar = [91, 90.4, 89.54, 89.97]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "rects1 = ax.bar(x - width/2, model, width, label='proposed model')\n",
    "rects2 = ax.bar(x + width/2, model_qumar, width, label='Sikder et al')\n",
    "\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Comparison with Niloy Sikder model')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend(loc='center')\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}%'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
